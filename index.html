
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>MT-Opt</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

        <!--FACEBOOK-->
    <meta property="og:image" content="https://karolhausman.github.com/mt-opt/img/arm-farm.gif">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="682">
    <meta property="og:image:height" content="682">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://karolhausman.github.io/mt-opt/"/>
    <meta property="og:title" content="MT-Opt" />
    <meta property="og:description" content="Project page for MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale." />

        <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="MT-Opt" />
    <meta name="twitter:description" content="Project page for MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale." />
    <meta name="twitter:image" content="https://karolhausman.github.com/mt-opt/img/arm-farm.gif" />


<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <!-- <link rel="icon" type="image/png" href="img/seal_icon.png"> -->
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>MT-Opt</b>: Continuous Multi-Task <br> Robotic Reinforcement Learning </br> 
                <small>
                    arXiv 2021
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                          Dmitry Kalashnikov*
                    </li>
                    <li>
                        <a href="http://www.cs.columbia.edu/~jvarley/">
                            Jake Varley*
                        </a>
                    </li>
                    <li>
                        <a href="http://www-clmc.usc.edu/Main/YevgenChebotar">
                          Yevgen Chebotar
                        </a>
                    </li>
                    <li>
                          Ben Swanson
                    </li><br>
                    <li>
                        <a href="http://ricojonschkowski.com/">
                          Rico Jonschkowski
                        </a>
                    </li>
                    <li>
                        <a href="https://ai.stanford.edu/~cbfinn/">
                          Chelsea Finn
                        </a>
                    </li>
                    <li>
                        <a href="http://people.eecs.berkeley.edu/~svlevine/">
                          Sergey Levine
                        </a>
                    </li>
                    <li>
                        <a href="https://karolhausman.github.io/">
                          Karol Hausman*
                        </a>
                    </li><br><br>
                    <a href="https://research.google/teams/brain/robotics/">
                    <image src="img/robotics-at-google.png" height="40px"> Robotics at Google</a> <br><br>
                    * equal contribution
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="go/mt-opt">
                            <image src="img/mip_paper_image.jpg" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://www.youtube.com/watch?v=H00-gNywtic">
                            <image src="img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="go/mt-am-blogpost">
                            <image src="img/google-ai-blog-small.png" height="60px">
                                <h4><strong>Blogpost</strong></h4>
                            </a>
                        </li>
                        <!-- <li>
                            <a href="https://github.com/">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li> -->
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p style="text-align:center;">
        	    <image src="img/arm-farm.gif" class="img-responsive">
                </p>
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
General-purpose robotic systems must master a large repertoire of diverse skills to be useful in a range of daily tasks. While reinforcement learning provides a powerful framework for acquiring individual behaviors, the time needed to acquire each skill makes the prospect of a generalist robot trained with RL daunting. In this paper, we study how a large-scale collective robotic learning system can acquire a repertoire of behaviors simultaneously, sharing exploration, experience, and representations across tasks. To instantiate this system, we develop a scalable and intuitive framework for specifying new tasks through user-provided examples of desired outcomes, devise a multi-robot collective learning system for data collection that simultaneously collects experience for multiple tasks, and develop a scalable and generalizable multi-task deep reinforcement learning method, which we call MT-Opt. We demonstrate how MT-Opt can learn a wide range of skills, including semantic picking (i.e., picking an object from a particular category), placing into various fixtures (e.g., placing a food item onto a plate), covering, aligning, and rearranging. We train and evaluate our system on a set of 12 real-world tasks with data collected from 7 robots, and demonstrate the performance of our system both in terms of its ability to generalize to structurally similar new tasks, and acquire distinct new tasks more quickly by leveraging past experience.
                </p>
            </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/H00-gNywtic" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
            	<br>
                <h3>
                    Approach
                </h3>
                <p class="text-justify">
                To collect diverse, multi-task data at scale, we create an intuitive success-detector-based approach that allows us to quickly define new tasks and their rewards. We train a multi-task success detector using data from all the tasks and continuously update it to accommodate for distribution shifts caused by various real-world factors such as varying lighting conditions and changing background surroundings. In addition, we provide a data collection strategy to simultaneously collect data for multiple distinct tasks across multiple robots. In this strategy, we use solutions to easier tasks to effectively bootstrap learning of more complex tasks. Over time, this allows us to start training a policy for the harder tasks, and consequently, to collect better data for those tasks.
                </p>
                <p style="text-align:center;">
                    <image src="img/mt-opt.gif"  class="img-responsive" height="600px">
                </p>
                <p class="text-justify">
            	The robots generate episodes which then get labelled as success or failure for the current task. These episodes are then copied and shared across other tasks to increase the learning efficiency. The balanced batch of episodes is then sent to our multi-task RL training pipeline to train the MT-Opt policy.
            </div>
        </div>
            

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results
                </h3>
                <p class="text-justify">
                    We train MT-Opt on a dataset of 9600 robot hours collected with 7 robots. We use offline multi-task reinforcement learning, and learn a wide variety of skills that include picking specific objects, placing them into various fixtures, aligning items on a rack, rearranging and covering objects with towels.
                </p>                
                <br>
	        <p style="text-align:center;">
                    <image src="img/mt-opt-grid.gif" class="img-responsive" height="400px">
                </p>
                <br>
                <p class="text-justify">
                    When compared to single-task baselines, our MT-Opt system performs similarly on the tasks that have the most data (e.g. generic lifting task at 89% success), while significantly improving performance of tasks underrepresented in the dataset - 50% average success rate on rare tasks compared to 1% achieved with a single-task QT-Opt baseline and 18% success achieved with a naive multi-task QT-Opt baseline.
                </p>
	        <p style="text-align:center;">
                    <image src="img/results.png" class="img-responsive" height="400px">
                </p>
                <br>
                <p class="text-justify">
                    Using this large pre-trained model not only can we generalize to new but similar tasks in zero-shot, but also we can quickly (in ~2 days of data collection on 7 robots) fine-tune our system to new, previously unseen tasks, such as a towel-covering task shown below (resulting in 92% success rate of towel-picking and 79% success rate of object-covering), which wasnâ€™t present in our original dataset.
                </p>
	        <p style="text-align:center;">
                    <image src="img/cover.gif" class="img-responsive" height="400px">
                </p>     
            </div>
        </div>


        
            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{mtopt2021arxiv,
    title={MT-OPT:
    Continuous Multi-Task Robotic Reinforcement Learning at Scale},
    author={Dmitry Kalashnkov and Jake Varley and 
            Yevgen Chebotar and Ben Swanson and 
            Rico Jonschkowski and Chelsea Finn and 
            Sergey Levine and Karol Hausman},
    journal={arXiv},
    year={2021}
}</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                We thank Josh Weaver, Noah Brown and Brandon Kinman for their robot operation support. We also thank Yao Lu and Anthony Brohan for their help with distributed learning and testing infrastructure.  Tom Small for help with videos and project media. Tuna Toksoz and Garrett Peake for improving the bin reset mechanisms. Satoshi Kataoka,  Michael Ahn, and Ken Oslund for help with the underlying control stack. The above contributions were incredibly enabling for this project.
                    <br><br>
                The website template was borrowed from <a href="http://jonbarron.info/">Jon Barron</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
